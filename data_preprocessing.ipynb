{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["eUx_b7-dqzeL","TSAl-H6viCYq"],"authorship_tag":"ABX9TyOL9puYziEasqYG/Tuey9qf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 초기 설정"],"metadata":{"id":"_YrAG96YloX6"}},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wMVBDdYQlhTs","executionInfo":{"status":"ok","timestamp":1691563140283,"user_tz":-540,"elapsed":7179,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"41cbc6d3-3c4d-4e69-f55d-a84ec0be0cba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/광인사_로악귀/[광인사] 1차 프로젝트/코드정리/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iX56XzQlln9B","executionInfo":{"status":"ok","timestamp":1691563144727,"user_tz":-540,"elapsed":1203,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"4079bbb8-ceea-4611-f09a-451b97273e0e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1rlRbTHMt0NUEyP8qWoMFBsBO1r3KNnsD/[광인사] 1차 프로젝트/코드정리\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import pytz\n","import unicodedata"],"metadata":{"id":"J0zmJWTJl2TW","executionInfo":{"status":"ok","timestamp":1691563147719,"user_tz":-540,"elapsed":2,"user":{"displayName":"이현호","userId":"13155778153693749241"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 현재 시각\n","korea_timezone = pytz.timezone('Asia/Seoul')\n","now = datetime.now(korea_timezone)\n","\n","path = '/content/gdrive/MyDrive/광인사_로악귀/[광인사] 1차 프로젝트/코드정리/'"],"metadata":{"id":"QiSxLIQTn7BB","executionInfo":{"status":"ok","timestamp":1691563154433,"user_tz":-540,"elapsed":372,"user":{"displayName":"이현호","userId":"13155778153693749241"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# 아이템 목록"],"metadata":{"id":"4ynsUEWHoFYB"}},{"cell_type":"code","source":["items_name =  [\n","    '한기',\n","    '무결점 골든 베릴',\n","    '시브의 보조장비 보주',\n","    '왜곡된 차원의 큐브[교환가능]',\n","    '진정한 각성을 이룬 자',\n","    '초전도 에너지 코어 상자[1회 교환가능]',\n","    '백룡의 뿔',\n","    '균열의 단편',\n","    '무결점 라이언 코어',\n","    '무결점 조화의 결정체',\n","    '견고한 수호자의 모래시계',\n","    '수호자의 모래시계',\n","    '기민한 흑룡의 날개',\n","    '차오르는 수호자의 망토',\n","    '눈부신 황혼의 공명',\n","    '차오르는 수호자의 모래시계',\n","    '날카로운 흑룡의 날개',\n","    '기운찬 적룡의 뿔',\n","    '기운찬 백룡의 뿔',\n","    '황금빛 황혼의 공명',\n","    '조화로운 흑룡의 뿔',\n","    '조화로운 적룡의 뿔',\n","    '조화로운 백룡의 뿔',\n","    '기민한 적룡의 날개',\n","    '칠흑같은 황혼의 공명',\n","    '조화로운 청룡의 뿔',\n","    '기운찬 청룡의 뿔',\n","    '빛을 머금은 이슬',\n","    '기운찬 흑룡의 뿔',\n","    '기민한 백룡의 날개',\n","    '날카로운 청룡의 날개',\n","    '날카로운 적룡의 날개',\n","    '조화로운 황룡의 뿔',\n","    '기민한 청룡의 날개',\n","    '타오르는 영원의 달빛',\n","    '기운찬 황룡의 뿔',\n","    '날카로운 백룡의 날개',\n","    '기운찬 비룡의 갈기',\n","    '타오르는 황혼의 공명',\n","    '비룡의 기운찬 발톱',\n","    '비룡의 기운찬 비늘',\n","    '태양을 삼킨 달',\n","    '맹렬한 비룡의 심장',\n","    '거룩한 저주의 서',\n","    '비룡의 단단한 발톱',\n","    '축제의 여왕 페리아 알',\n","    '워터밤 페스타 아바타[시크릿] 풀세트 상자[여자]',\n","    '페스타의 추억 칭호 상자'\n","]"],"metadata":{"id":"nsjgtQqcoCng","executionInfo":{"status":"ok","timestamp":1691563161142,"user_tz":-540,"elapsed":418,"user":{"displayName":"이현호","userId":"13155778153693749241"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# 전처리 함수 (이전 거래내역 추가)"],"metadata":{"id":"eUx_b7-dqzeL"}},{"cell_type":"code","source":["# 거래 요일, 거래 시간 column 추가\n","# 거래 요일 one-hot-encoding\n","def preprocessing_data(path, items_name):\n","    # 현재 경로에 존재하는 통합본 리스트\n","    file_list = os.listdir(path + 'merged_file/')\n","\n","    for item_name in items_name:\n","        # 각 아이템 이름의 통합본을 하나씩 추출해서 데이터프레임으로 전환\n","        uni = unicodedata.normalize('NFD',item_name)\n","        item_list = [file for file in file_list if file.find(f'{uni}_merged.csv') != -1]\n","        print(item_list)\n","        df = pd.read_csv(path + 'merged_file/' + item_list[0])\n","\n","        # 판매 날짜를 date 타입으로 변환\n","        df['soldDate'] = pd.to_datetime(df['soldDate'])\n","\n","        # 요일, 시간 column 추가\n","        df['day_of_week'] = df['soldDate'].dt.day_name()\n","        df['hour'] = df['soldDate'].dt.hour\n","        df['day'] = df['soldDate'].dt.day\n","        df['month'] = df['soldDate'].dt.month\n","\n","        window_size = 3\n","\n","        # Create new columns for past unitPrice values\n","        for i in range(window_size):\n","          df[f'unitPrice_past_{i}'] = df['unitPrice'].shift(i+1)\n","\n","        # Drop the first few rows which have NaN values due to the shift operation\n","        df = df.iloc[window_size:].reset_index(drop=True)\n","\n","        # Rearrange columns                                                                                                                 # 여기서 추출할 column 재정의\n","        df_new = df[['count', 'hour', 'day_of_week'] + [f'unitPrice_past_{i}' for i in range(window_size)] + ['unitPrice']]\n","\n","        # 거래 요일 one-hot-encoding\n","        df_new = pd.get_dummies(df_new, columns=['day_of_week'])\n","        df_new.to_csv(path + 'preprocessing_file/' + item_name+\"_merged\"+\"_preprocessing.csv\", index=False, encoding='utf-8-sig')                                    # 여기서 파일명 전처리에 맞게 변경해서 저장\n","\n","preprocessing_data(path, items_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1r8ek4Miq0d_","executionInfo":{"status":"ok","timestamp":1691471125413,"user_tz":-540,"elapsed":2606,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"6c06e82b-e5c1-4116-a6d6-00140b50d107"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['한기_merged.csv']\n","['무결점 골든 베릴_merged.csv']\n","['시브의 보조장비 보주_merged.csv']\n","['왜곡된 차원의 큐브[교환가능]_merged.csv']\n","['진정한 각성을 이룬 자_merged.csv']\n","['초전도 에너지 코어 상자[1회 교환가능]_merged.csv']\n","['백룡의 뿔_merged.csv', '기운찬 백룡의 뿔_merged.csv', '조화로운 백룡의 뿔_merged.csv']\n","['균열의 단편_merged.csv']\n","['무결점 라이언 코어_merged.csv']\n","['무결점 조화의 결정체_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv', '수호자의 모래시계_merged.csv', '차오르는 수호자의 모래시계_merged.csv']\n","['기민한 흑룡의 날개_merged.csv']\n","['차오르는 수호자의 망토_merged.csv']\n","['눈부신 황혼의 공명_merged.csv']\n","['차오르는 수호자의 모래시계_merged.csv']\n","['날카로운 흑룡의 날개_merged.csv']\n","['기운찬 적룡의 뿔_merged.csv']\n","['기운찬 백룡의 뿔_merged.csv']\n","['황금빛 황혼의 공명_merged.csv']\n","['조화로운 흑룡의 뿔_merged.csv']\n","['조화로운 적룡의 뿔_merged.csv']\n","['조화로운 백룡의 뿔_merged.csv']\n","['기민한 적룡의 날개_merged.csv']\n","['칠흑같은 황혼의 공명_merged.csv']\n","['조화로운 청룡의 뿔_merged.csv']\n","['기운찬 청룡의 뿔_merged.csv']\n","['빛을 머금은 이슬_merged.csv']\n","['기운찬 흑룡의 뿔_merged.csv']\n","['기민한 백룡의 날개_merged.csv']\n","['날카로운 청룡의 날개_merged.csv']\n","['날카로운 적룡의 날개_merged.csv']\n","['조화로운 황룡의 뿔_merged.csv']\n","['기민한 청룡의 날개_merged.csv']\n","['타오르는 영원의 달빛_merged.csv']\n","['기운찬 황룡의 뿔_merged.csv']\n","['날카로운 백룡의 날개_merged.csv']\n","['기운찬 비룡의 갈기_merged.csv']\n","['타오르는 황혼의 공명_merged.csv']\n","['비룡의 기운찬 발톱_merged.csv']\n","['비룡의 기운찬 비늘_merged.csv']\n","['태양을 삼킨 달_merged.csv']\n","['맹렬한 비룡의 심장_merged.csv']\n","['거룩한 저주의 서_merged.csv']\n","['비룡의 단단한 발톱_merged.csv']\n","['축제의 여왕 페리아 알_merged.csv']\n","['워터밤 페스타 아바타[시크릿] 풀세트 상자[여자]_merged.csv']\n","['페스타의 추억 칭호 상자_merged.csv']\n"]}]},{"cell_type":"markdown","source":["# 전처리 2 (날짜 없이 이전 데이터만)"],"metadata":{"id":"TSAl-H6viCYq"}},{"cell_type":"code","source":["# 거래 요일, 거래 시간 column 추가\n","# 거래 요일 one-hot-encoding\n","def preprocessing_data(path, items_name):\n","    # 현재 경로에 존재하는 통합본 리스트\n","    file_list = os.listdir(path + 'merged_file/')\n","\n","    for item_name in items_name:\n","        # 각 아이템 이름의 통합본을 하나씩 추출해서 데이터프레임으로 전환\n","        uni = unicodedata.normalize('NFD',item_name)\n","        item_list = [file for file in file_list if file.find(f'{uni}_merged.csv') != -1]\n","        print(item_list)\n","        df = pd.read_csv(path + 'merged_file/' + item_list[0])\n","\n","        # # 판매 날짜를 date 타입으로 변환\n","        # df['soldDate'] = pd.to_datetime(df['soldDate'])\n","\n","        # # 요일, 시간 column 추가\n","        # df['day_of_week'] = df['soldDate'].dt.day_name()\n","        # df['hour'] = df['soldDate'].dt.hour\n","        # df['day'] = df['soldDate'].dt.day\n","        # df['month'] = df['soldDate'].dt.month\n","\n","        window_size = 3\n","\n","        # Create new columns for past unitPrice values\n","        for i in range(window_size):\n","          df[f'unitPrice_past_{i}'] = df['unitPrice'].shift(i+1)\n","\n","        # Drop the first few rows which have NaN values due to the shift operation\n","        df = df.iloc[window_size:].reset_index(drop=True)\n","\n","        # Rearrange columns                                                                                                                 # 여기서 추출할 column 재정의\n","        df_new = df[[f'unitPrice_past_{i}' for i in range(window_size)] + ['unitPrice']]\n","\n","        # 거래 요일 one-hot-encoding\n","        # df_new = pd.get_dummies(df_new, columns=['day_of_week'])\n","        df_new.to_csv(path + 'preprocessing_file/' + item_name+\"_merged\"+\"_preprocessing.csv\", index=False, encoding='utf-8-sig')                                    # 여기서 파일명 전처리에 맞게 변경해서 저장\n","\n","preprocessing_data(path, items_name)"],"metadata":{"id":"xadlgE-Att8U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691558778753,"user_tz":-540,"elapsed":2416,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"86876bac-85d2-4ba7-e939-6e52102758e6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['한기_merged.csv']\n","['무결점 골든 베릴_merged.csv']\n","['시브의 보조장비 보주_merged.csv']\n","['왜곡된 차원의 큐브[교환가능]_merged.csv']\n","['진정한 각성을 이룬 자_merged.csv']\n","['초전도 에너지 코어 상자[1회 교환가능]_merged.csv']\n","['기운찬 백룡의 뿔_merged.csv', '조화로운 백룡의 뿔_merged.csv', '백룡의 뿔_merged.csv']\n","['균열의 단편_merged.csv']\n","['무결점 라이언 코어_merged.csv']\n","['무결점 조화의 결정체_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv', '차오르는 수호자의 모래시계_merged.csv', '수호자의 모래시계_merged.csv']\n","['기민한 흑룡의 날개_merged.csv']\n","['차오르는 수호자의 망토_merged.csv']\n","['눈부신 황혼의 공명_merged.csv']\n","['차오르는 수호자의 모래시계_merged.csv']\n","['날카로운 흑룡의 날개_merged.csv']\n","['기운찬 적룡의 뿔_merged.csv']\n","['기운찬 백룡의 뿔_merged.csv']\n","['황금빛 황혼의 공명_merged.csv']\n","['조화로운 흑룡의 뿔_merged.csv']\n","['조화로운 적룡의 뿔_merged.csv']\n","['조화로운 백룡의 뿔_merged.csv']\n","['기민한 적룡의 날개_merged.csv']\n","['칠흑같은 황혼의 공명_merged.csv']\n","['조화로운 청룡의 뿔_merged.csv']\n","['기운찬 청룡의 뿔_merged.csv']\n","['빛을 머금은 이슬_merged.csv']\n","['기운찬 흑룡의 뿔_merged.csv']\n","['기민한 백룡의 날개_merged.csv']\n","['날카로운 청룡의 날개_merged.csv']\n","['날카로운 적룡의 날개_merged.csv']\n","['조화로운 황룡의 뿔_merged.csv']\n","['기민한 청룡의 날개_merged.csv']\n","['타오르는 영원의 달빛_merged.csv']\n","['기운찬 황룡의 뿔_merged.csv']\n","['날카로운 백룡의 날개_merged.csv']\n","['기운찬 비룡의 갈기_merged.csv']\n","['타오르는 황혼의 공명_merged.csv']\n","['비룡의 기운찬 발톱_merged.csv']\n","['비룡의 기운찬 비늘_merged.csv']\n","['태양을 삼킨 달_merged.csv']\n","['맹렬한 비룡의 심장_merged.csv']\n","['거룩한 저주의 서_merged.csv']\n","['비룡의 단단한 발톱_merged.csv']\n","['축제의 여왕 페리아 알_merged.csv']\n","['워터밤 페스타 아바타[시크릿] 풀세트 상자[여자]_merged.csv']\n","['페스타의 추억 칭호 상자_merged.csv']\n"]}]},{"cell_type":"markdown","source":["# 전처리 3 (월(one-hot), 일(one-hot), 시간(one-hot), 분(one-hot), 요일(one-hot), 수량, 단위가격)"],"metadata":{"id":"wLJHB-flwPhI"}},{"cell_type":"code","source":["# 거래 요일, 거래 시간 column 추가\n","# 거래 요일 one-hot-encoding\n","def preprocessing_data(path, items_name):\n","    # 현재 경로에 존재하는 통합본 리스트\n","    file_list = os.listdir(path+'merged_file/')\n","\n","    for item_name in items_name:\n","        # 각 아이템 이름의 통합본을 하나씩 추출해서 데이터프레임으로 전환\n","        uni = unicodedata.normalize('NFD',item_name)\n","        item_list = [file for file in file_list if file.find(f'{uni}_merged.csv') != -1]\n","        print(item_list)\n","        df = pd.read_csv(path + 'merged_file/' + item_list[0])\n","\n","        # 판매 날짜를 date 타입으로 변환\n","        df['soldDate'] = pd.to_datetime(df['soldDate'])\n","\n","        # 요일, 시간 column 추가\n","        df['day_of_week'] = df['soldDate'].dt.day_name()\n","        df['hour'] = df['soldDate'].dt.hour\n","        df['day'] = df['soldDate'].dt.day\n","        df['month'] = df['soldDate'].dt.month\n","        df['minute'] = df['soldDate'].dt.minute\n","\n","        # Rearrange columns                                                                                                                 # 여기서 추출할 column 재정의\n","        df_new = df[['month', 'day', 'hour', 'minute', 'day_of_week', 'count', 'unitPrice']]\n","\n","        # 거래 요일 one-hot-encoding\n","        df_new = pd.get_dummies(df_new, columns=['month', 'day', 'hour', 'minute', 'day_of_week'])\n","        df_new.to_csv(path + 'preprocessing_file/' + item_name+\"_merged\"+\"_preprocessing.csv\", index=False, encoding='utf-8-sig')                                    # 여기서 파일명 전처리에 맞게 변경해서 저장\n","\n","preprocessing_data(path, items_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObHLInOLRseW","executionInfo":{"status":"ok","timestamp":1691508621147,"user_tz":-540,"elapsed":1116,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"bcea58a5-8168-4434-b625-b46616c96f97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['기운찬 백룡의 뿔_merged.csv', '조화로운 백룡의 뿔_merged.csv', '백룡의 뿔_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv', '차오르는 수호자의 모래시계_merged.csv', '수호자의 모래시계_merged.csv']\n"]}]},{"cell_type":"markdown","source":["# 전처리 4 (월, 일, 시간(one-hot), 분(one-hot), 요일(one-hot), 수량, 단위가격)"],"metadata":{"id":"uEcVL46_5PH0"}},{"cell_type":"code","source":["# 거래 요일, 거래 시간 column 추가\n","# 거래 요일 one-hot-encoding\n","def preprocessing_data(path, items_name):\n","    # 현재 경로에 존재하는 통합본 리스트\n","    file_list = os.listdir(path+'merged_file/')\n","\n","    for item_name in items_name:\n","        # 각 아이템 이름의 통합본을 하나씩 추출해서 데이터프레임으로 전환\n","        uni = unicodedata.normalize('NFD',item_name)\n","        item_list = [file for file in file_list if file.find(f'{uni}_merged.csv') != -1]\n","        print(item_list)\n","        df = pd.read_csv(path + 'merged_file/' + item_list[0])\n","\n","        # 판매 날짜를 date 타입으로 변환\n","        df['soldDate'] = pd.to_datetime(df['soldDate'])\n","\n","        # 요일, 시간 column 추가\n","        df['day_of_week'] = df['soldDate'].dt.day_name()\n","        df['hour'] = df['soldDate'].dt.hour\n","        df['day'] = df['soldDate'].dt.day\n","        df['month'] = df['soldDate'].dt.month\n","        df['minute'] = df['soldDate'].dt.minute\n","\n","        # Rearrange columns                                                                                                                 # 여기서 추출할 column 재정의\n","        df_new = df[['month', 'day', 'hour', 'minute', 'day_of_week', 'count', 'unitPrice']]\n","\n","        # 거래 요일 one-hot-encoding\n","        df_new = pd.get_dummies(df_new, columns=['hour', 'minute', 'day_of_week'])\n","        df_new.to_csv(path + 'preprocessing_file/' + item_name+\"_merged\"+\"_preprocessing.csv\", index=False, encoding='utf-8-sig')           # 여기서 파일명 전처리에 맞게 변경해서 저장\n","\n","preprocessing_data(path, items_name)"],"metadata":{"id":"qt4v9fc8S9BV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691544654700,"user_tz":-540,"elapsed":1554,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"76dcef2f-4e77-4c29-9c1e-1371a592d89e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['기운찬 백룡의 뿔_merged.csv', '조화로운 백룡의 뿔_merged.csv', '백룡의 뿔_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv', '차오르는 수호자의 모래시계_merged.csv', '수호자의 모래시계_merged.csv']\n"]}]},{"cell_type":"markdown","source":["# 전처리 5 (월(one-hot), 일(one-hot), 시간(one-hot), 요일(one-hot), 단위가격)"],"metadata":{"id":"qKRKQ1vuBWyk"}},{"cell_type":"code","source":["# 거래 요일, 거래 시간 column 추가\n","# 거래 요일 one-hot-encoding\n","def preprocessing_data(path, items_name):\n","    # 현재 경로에 존재하는 통합본 리스트\n","    file_list = os.listdir(path+'merged_file/')\n","\n","    for item_name in items_name:\n","        # 각 아이템 이름의 통합본을 하나씩 추출해서 데이터프레임으로 전환\n","        uni = unicodedata.normalize('NFD',item_name)\n","        item_list = [file for file in file_list if file.find(f'{uni}_merged.csv') != -1]\n","        print(item_list)\n","        df = pd.read_csv(path + 'merged_file/' + item_list[-1])\n","\n","        # 판매 날짜를 date 타입으로 변환\n","        df['soldDate'] = pd.to_datetime(df['soldDate'])\n","\n","        # 요일, 시간 column 추가\n","        df['day_of_week'] = df['soldDate'].dt.day_name()\n","        df['hour'] = df['soldDate'].dt.hour\n","        df['day'] = df['soldDate'].dt.day\n","        df['month'] = df['soldDate'].dt.month\n","        df['minute'] = df['soldDate'].dt.minute\n","\n","        # Rearrange columns                                                                                                                 # 여기서 추출할 column 재정의\n","        df_new = df[['month', 'day', 'hour', 'day_of_week', 'unitPrice']]\n","\n","        # 거래 요일 one-hot-encoding\n","        df_new = pd.get_dummies(df_new, columns=['month', 'day', 'hour', 'day_of_week'])\n","        df_new.to_csv(path + 'preprocessing_file/' + item_name+\"_merged\"+\"_preprocessing.csv\", index=False, encoding='utf-8-sig')           # 여기서 파일명 전처리에 맞게 변경해서 저장\n","\n","preprocessing_data(path, items_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZtLiK8x6C9r","executionInfo":{"status":"ok","timestamp":1691557483543,"user_tz":-540,"elapsed":29211,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"5f28535a-526d-42ef-9569-0191f96e71e6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['한기_merged.csv']\n","['무결점 골든 베릴_merged.csv']\n","['시브의 보조장비 보주_merged.csv']\n","['왜곡된 차원의 큐브[교환가능]_merged.csv']\n","['진정한 각성을 이룬 자_merged.csv']\n","['초전도 에너지 코어 상자[1회 교환가능]_merged.csv']\n","['기운찬 백룡의 뿔_merged.csv', '조화로운 백룡의 뿔_merged.csv', '백룡의 뿔_merged.csv']\n","['균열의 단편_merged.csv']\n","['무결점 라이언 코어_merged.csv']\n","['무결점 조화의 결정체_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv']\n","['견고한 수호자의 모래시계_merged.csv', '차오르는 수호자의 모래시계_merged.csv', '수호자의 모래시계_merged.csv']\n","['기민한 흑룡의 날개_merged.csv']\n","['차오르는 수호자의 망토_merged.csv']\n","['눈부신 황혼의 공명_merged.csv']\n","['차오르는 수호자의 모래시계_merged.csv']\n","['날카로운 흑룡의 날개_merged.csv']\n","['기운찬 적룡의 뿔_merged.csv']\n","['기운찬 백룡의 뿔_merged.csv']\n","['황금빛 황혼의 공명_merged.csv']\n","['조화로운 흑룡의 뿔_merged.csv']\n","['조화로운 적룡의 뿔_merged.csv']\n","['조화로운 백룡의 뿔_merged.csv']\n","['기민한 적룡의 날개_merged.csv']\n","['칠흑같은 황혼의 공명_merged.csv']\n","['조화로운 청룡의 뿔_merged.csv']\n","['기운찬 청룡의 뿔_merged.csv']\n","['빛을 머금은 이슬_merged.csv']\n","['기운찬 흑룡의 뿔_merged.csv']\n","['기민한 백룡의 날개_merged.csv']\n","['날카로운 청룡의 날개_merged.csv']\n","['날카로운 적룡의 날개_merged.csv']\n","['조화로운 황룡의 뿔_merged.csv']\n","['기민한 청룡의 날개_merged.csv']\n","['타오르는 영원의 달빛_merged.csv']\n","['기운찬 황룡의 뿔_merged.csv']\n","['날카로운 백룡의 날개_merged.csv']\n","['기운찬 비룡의 갈기_merged.csv']\n","['타오르는 황혼의 공명_merged.csv']\n","['비룡의 기운찬 발톱_merged.csv']\n","['비룡의 기운찬 비늘_merged.csv']\n","['태양을 삼킨 달_merged.csv']\n","['맹렬한 비룡의 심장_merged.csv']\n","['거룩한 저주의 서_merged.csv']\n","['비룡의 단단한 발톱_merged.csv']\n","['축제의 여왕 페리아 알_merged.csv']\n","['워터밤 페스타 아바타[시크릿] 풀세트 상자[여자]_merged.csv']\n","['페스타의 추억 칭호 상자_merged.csv']\n"]}]},{"cell_type":"markdown","source":["# 전처리 6"],"metadata":{"id":"zGgVz5fpCxcv"}},{"cell_type":"code","source":["# 거래 요일, 거래 시간 column 추가\n","# 거래 요일 one-hot-encoding\n","def preprocessing_data(path, items_name):\n","    # 현재 경로에 존재하는 통합본 리스트\n","    file_list = os.listdir(path + 'merged_file/')\n","\n","    for item_name in items_name:\n","        # 각 아이템 이름의 통합본을 하나씩 추출해서 데이터프레임으로 전환\n","        uni = unicodedata.normalize('NFD',item_name)\n","        item_list = [file for file in file_list if file.find(f'{uni}_merged.csv') != -1]\n","        print(item_list)\n","        df = pd.read_csv(path + 'merged_file/' + item_list[0])\n","\n","        # 판매 날짜를 date 타입으로 변환\n","        df['soldDate'] = pd.to_datetime(df['soldDate'])\n","\n","        # 요일, 시간 column 추가\n","        df['day_of_week'] = df['soldDate'].dt.day_name()\n","        df['hour'] = df['soldDate'].dt.hour\n","        df['day'] = df['soldDate'].dt.day\n","        df['month'] = df['soldDate'].dt.month\n","\n","        # 시간별 평균값으로 통합\n","        merged_df = df.drop_duplicates(subset=['month','day', 'hour'], keep='first')\n","        merged_df[\"unitPrice\"] = 0\n","        merged_df.reset_index(drop=True, inplace=True)\n","        for i,month,day,hour in zip(range(len(merged_df)),merged_df.loc[:,'month'], merged_df.loc[:,'day'], merged_df.loc[:,'hour']):\n","          merged_df[\"unitPrice\"][i] = df[\"unitPrice\"][(df.month == month) & (df.day == day) & (df.hour == hour)].median()\n","\n","        window_size = 3\n","\n","        # Create new columns for past unitPrice values\n","        for i in range(window_size):\n","          merged_df[f'unitPrice_past_{i}'] = merged_df['unitPrice'].shift(i+1)\n","\n","        # Drop the first few rows which have NaN values due to the shift operation\n","        mreged_df = merged_df.iloc[window_size:].reset_index(drop=True)\n","\n","        # Rearrange columns                                                                                                                 # 여기서 추출할 column 재정의\n","        df_new = merged_df[[f'unitPrice_past_{i}' for i in range(window_size)] + ['unitPrice']]\n","\n","        # 거래 요일 one-hot-encoding\n","        # df_new = pd.get_dummies(df_new, columns=['day_of_week'])\n","        df_new.to_csv(path + 'preprocessing_file/' + item_name+\"_merged\"+\"_preprocessing.csv\", index=False, encoding='utf-8-sig')           # 여기서 파일명 전처리에 맞게 변경해서 저장\n","\n","preprocessing_data(path, items_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1RELBwWjbDtUYBENgYE-EOftuEwXIqppy"},"id":"wq4FZ7pVB5xd","executionInfo":{"status":"ok","timestamp":1691564263613,"user_tz":-540,"elapsed":17329,"user":{"displayName":"이현호","userId":"13155778153693749241"}},"outputId":"7b976255-fe9e-40cf-8d22-d6f12655ee9c"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"Vjd9vooGEm8l"},"execution_count":null,"outputs":[]}]}